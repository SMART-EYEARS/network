# Proxy

DNS RR
Least Connection
최소 접속 방식
서버에 연결되어 있는 커넥션 개수만 갖고 단순 비교하여 가장 적은 곳에 연결
Weighted Least Connections
가중치 최소 접속 방식
서버에 부여된 Weight값을 기반으로 커넥션 수의 개수와 함께 고려하여 연결
Fastest Response Time
응답시간방식
가장 빨리 응답하는 서버에 이용자 요구를 연결하는 방법
응답시간은 각 서버가 패킷 형태의 요구를 송수신하는데 걸리는 시간을 측정한 것이다
Adaptive
최소대기방식
Open 또는 Pending중인 커넥션을 적게 가지고 있는 서버로 네트워크 커넥션 방향을 지정한다
Pending 커넥션은 Full TCP Handshake를 완성하지 않은 것으로, 이것은 초당 클라이언트 Thread의 수가 증가할 때 더욱 잘 수행된다
Hash
특정 클라이언트는 특정 서버로만 할당시키는 방법
경로가 보장되며 접속자수가 많을수록 분산 및 효율이 뛰어나다
다만 접속자수가 적을수록 공평하게 분산이 안될수도 있다
보통 단순하게 한가지 알고리즘만 선택하지 않고 Least Connection 알고리즘 선택 후 동등한 수의 Connection일 경우 Round Robin을 선택하는 방식으로 결합하여 사용한다.
 

로드밸런서 동작방식(Mode 별)
DSR(Direct Server Return) 방식
서버에서 결과를 바로 클라이언트에게 리턴
이러한 모드가 나온 배경은, 인바운드 트래픽 대비 아웃바운드의 트래픽이 높아 나오게됨
기존은 Client -> L4 -> Server -> L4 -> Client 이렇게 됨. L4에 인바운드, 아웃바운드 트래픽이 모두 물려 부하가 크고 리소스 소모가 큼
이러한 문제를 해결하기 위해 나온 DSR은 이렇게 동작함: Client -> L4 -> Server -> Client
아웃바운드 트래픽을 L4에 전달하지 않고 직접 클라이언트에게 전달함
사용자가 real server에 접근할 때 출발지와 목적지의 IP 주소를 변조하지 않고, L4에서 관리하는 real server의 MAC 주소 테이블을 확인해서 MAC주소만 변조한다.
클라이언트의 Request를 서버로 전달함에 있어 어떤 헤더를 이용하는지에 따라 L2/L3 DSR로 구분하게 된다.
L2DSR : MAC 주소 변경을 통해 클라이언트의 Request가 전달
L3DSR : IP Header를 변조하여 서버에 Request를 전달
Bridge/Transparent Mode
사용자가 서비스를 요청하면 L4로 전달된 목적지 IP 주소를 REAL SERVER IP 주소로 변조하고 MAC 주소를 변조해서 목적지를 찾아가는 방식
요청 전달 시 변조 :
사용자 -> L4 -> NAT(IP/MAC 주소 변조) -> real server
사용자가 L4를 호출하면 중간에 NAT(Network Address Translation)가 목적지 IP 주소를 real server IP 주소로 변조하고 MAC 주소도 변조한다
응답 전달 시 변조 :
Real server -> NAT -> L4 -> 사용자
real server에서 L4를 거치면서 출발지(source) IP 주소를 L4 가상 IP 주소로 변조한다
동일 네트워크 대역이므로 MAC 주소는 변조하지 않는다
Router Mode
Bridge/Transparent Mode와 유사하지만 출발지(source) MAC 주소도 변조된다
One Arm Mode
사용자가 real server에 접근할 때 목적지 IP는 L4 스위치 IP를 바라본다.
L4에 도달하면 L4가 클라이언트에게 받은 목적지 IP 주소를 L4 IP 주소에서 real server IP와 real server MAC 주소로 변조한다
되돌아가는 IP는 L4의 IP pool의 IP 주소로 변조한다.
NAT(Network Address Translation)
private IP를 public IP로 바꾸는데 사용하는 통신망의 주소변조기
 

대표적인 로드밸런서
L4 (Transport Layer) :
OSI 7계층 중 4 Layer를 라우팅 하는 스위치
Transport Layer(IP + Port) Load Balancing
TCP, UDP 프로토콜
Port 기반 스위칭 지원
VIP(Virtual IP)를 이용하여 여러대를 한대로 묶어 부하 분산
주로 Round Robin 방식 사용
L7 (Application Layer) :
Application Layer(Client Request) Load Balancing
HTTP, FTP, SMTP, 프로토콜
 

오픈소스 로드밸런서 HAProxy
기존의 하드웨어 스위치를 대체하는 소프트웨어 로드밸런서로, 네트워크 스위치에서 제공하는 L4, L7 기능 및 로드밸런서 기능을 제공한다.
Proxy 
Forward Proxy :
클라이언트 앞단에 존재하며 프록시 서버가 클라이언트 대신 서버에 요청하고 전달받은 결과를 클라이언트에게 전달하는 역할 수행
Backend Server에게 Client를 숨길 때 사용
Client <=> Forward Proxy → Backend Server
Reverce Proxy :
실제 서버 요청에 대해서 서버 앞 단에 존재하면서, 서버로 들어오는 요청을 대신 받아서 서버에 전달하고 요청한 곳에 그 결과를 다시 전달하는 역할 수행
Client에게 Backend를 숨길 때 사용
Client → Reverse Proxy Server <=> Backend Server
HAProxy 기본 동작 방식 
HAProxy는 기본적으로 reverse proxy형태로 동작한다
1. 최초 접근 시 서버에 요청 전달
2. 응답 시 쿠키(cookie)에 서버 정보 추가 후 반환
3. 재요청 시 proxy에서 쿠키 정보 확인 -> 최초 요청 서버로 전달
다시 접근 시 쿠키 추가 없이 전달 -> 클라이언트에 쿠키 정보가 계속 존재함(쿠키 재사용)
참고 : https://d2.naver.com/helloworld/284659

HAProxy 동작방식
 

HAProxy를 운용하는 다양한 방법이 있으나, 상세한 내용은 링크를 참고할 것 

# ForwardProxy
# ReverseProxy


# 로드밸런서     
> 일반적으로 서버 앞단에 위치하여 클라이언트 측의 요청을 분산해주는 프로그램        
   
시대의 흐름, 기술의 발전으로 이전과는 비교가 되지 않을 만큼 데이터가 생성되며     
이러한 데이터, 트래픽을 처리해야하기 위한 기술들 또한 등장하게 되었다.    
         
**로드밸런서란?**              
서버에 가해지는 부하를 분산해주거나      
장애에 대응하기 위한 **장치 또는 기술**을 통칭한다.          
              
* **부하 분산:**        
L4 스위치를 통한 로드밸런싱으로 다수의 서버들이          
서버로드 및 트래픽 등 분산 알고리즘에 따라 분배되어 처리하는 기능         
        
* **FAIL OVER:**         
다수의 서버가 운영되다가 그 중 하나의 장비에서 장애가 발생하면       
해당 장비는 FAIL 처리되고 나머지 서버가 바로 정상 운영되는 방식      
     
여기서 중요한 것은 **장치** 또는 **기술**이라는 점이다.          
흔히 기술을 `로드밸런싱`이라고 생각할 수 있는데, 더 나아가 소프트웨어 로드밸런싱도 존재한다.      
대표적인 SW 로드밸런싱으로 [NGINX](https://ko.wikipedia.org/wiki/Nginx), [HAProxy](https://d2.naver.com/helloworld/284659) 그리고          
`Netflix`의 [Ribbon](https://github.com/Netflix/ribbon)이 있다. -> SpringBoot 2.4 에서부터 Netflix 의존성 점차 사라지기 시작할 예정         

로드 밸런서는 크게 2가지가 존재한다.   
     
- 운영체제 로드밸런서 : 물리적 프로세서간 작업 스케줄링 (사실, 운영체제 로드밸런서는 별개의 세상이다.)           
- 네트워크 로드밸런서: 사용가능한 백엔드에서 네트워크 작업 스케줄링  
         
다시 본론으로 돌아와, 로드밸런서는 그 종류와 분류가 너무 많다 😖        
그렇기 때문에 이번 로드밸런서 주제는 **HW** 그리고 **네트워크 로드밸런서**에 대해서 다루겠다.         
   
___  
   
앞서 로드 밸런서는 `서버에 가해지는 부하를 분산해주는 장치 또는 기술`이라 말했다.     
**그렇다면 모든 회사에서 로드밸런서를 사용하는 것이 좋지않을까? 🤔**            
   
로드밸런서는 주로 렌탈 형식으로 판매하는데 1G가 1년에 400만원, 비싼건 2000만원 까지도      
근데 중요한건 1개만 필요한게 아니라 여러 대가 필요하므로 회사 입장에서는 지출이 쎄다.       
      
그렇기 때문에 사업의 규모가 확장되고, 클라이언트의 수가 늘어나게 되어   
기존 서버만으로는 정상적인 서비스가 불가능하게 되었을 때 도입하면 된다.    
                    
**여담으로** 사업이 확장됨에 따라 증가되는 트래픽을 대처할 수 있는 방법은 크게 두 가지가 있다.  
      
* Scale up : 서버 자체의 성능을 높이는 것
* Scale out : 여러 대의 서버를 두는 것
         
`Scale up`은 쉽게 생각하면 기존 서버보다 성능이 좋은 서버로 교체한다고 생각해도 좋다.            
`Scale-out`은 기존의 서버외에도 추가로 서버를 중성하는 것을 의미하는데           
여러 대의 서버가 존재하면, 트래픽을 균등하게 분산해주어야 하므로 로드밸런싱이 반드시 필요하다.                  
 
# 로드 밸런서의 주요 기술    
* **NAT(Network Address Translation):**        
사설 IP 주소를 공인 IP 주소로 바꿀 때      
공인 IP 주소를 사설 IP 주소로 바꿀 때,     
사용하는 통신망의 주소 변조기이다.           
       
* **DSR(Dynamic Source Routing protocol):**          
로드 밸런서 사용 시 **서버에서 클라이언트로 되돌아가는 경우**      
목적지 주소를 스위치의 IP 주소가 아닌 클라이언트의 IP 주소로 전달해서      
네트워크 스위치를 거치지 않고 **바로 클라이언트를 찾아가는 개념이다.**     
         
* **Tunneling:**        
인터넷상에서 눈에 보이지 않는 통로를 만들어 통신할 수 있게 하는 개념으로,         
**데이터(패킷)를 캡슐화**해서 **연결된 상호 간에만** 캡슐화된 패킷을 구별해 **캡슐화를 해제**할 수 있다.     

# 로드밸런싱이 일어나는 과정
       
1. 클라이언트가 브라우저에 도메인 입력(e.g. abc.co.kr)
2. PC에 설정된 Local DNS 서버로 DNS Query 
3. Local DNS 서버는 abc.co.kr을 관리하는 DNS 서버에 DNS Query, 
4. **L4의 VIP주소 획득**  
5. Local DNS는 획득한 **VIP 주소를 Client에게 전송**   
6. 획득한 DNS를 기반으로 L4 VIP로 http 요청
7. L/B 장비는 내부 알고리즘 (라운드 로빈 등)을 통해 최적의 서비스 서버를 선별하여 요청을 전송하며 서버는 작업 결과를 L/B 장비로 전송
8. 전달받은 서버 작업 결과 L/B 장비 통해 Client로 전송하여 요청 처리 완료   
     
# 로드 밸런싱의 종류    
## L2(Data Link Layer)
L2 로드밸런싱 : Layer 2(Data Link 계층)에서 정의된 정보를 바탕으로 로드 밸런싱을 한다.       
               
- **MAC 주소**를 이용하여 전달할 서버를 결정한다.      
- 예시 : Mac > 80–00–20–30–1C-47
- 브릿지, 허브 등    
- 장점 : 구조가 간단, 신뢰성이 높다, 가격저렴, 성능이 좋다.  
- 단점 : **Broadcast 패킷에 의해 성능저하 발생**, 라우팅 등 상위Layer 프로토콜 기반 스위칭 불가    
     
L2 로드밸런싱 전략을 사용하기 위해서는          
**로드밸런서와 서버가 반드시 같은 네트워크에 속해야 한다.**             
L2 로드밸런싱의 **기준이 되는 데이터가 MAC 주소**이기 때문이다.          
       
## L3(Network Layer)
L4 로드 밸런싱 : Layer 3(Network 계층)의 정보를 바탕으로 부하를 분산한다.   

- **IP 주소**를 이용하여 전달할 서버를 결정한다.        
- 예시 : IP > 213.12.32.123
- L2 + Routing
- Router, ICMP 프로토콜, IP
- 장점: Broadcast 트래픽으로 전체 성능 저하 방지, 트레픽체크
- 단점: 특정 프로토콜을 이용해야 스위칭 가능
      
## L4(Transport Layer)
L4 로드 밸런싱 : Layer 4(Transport 계층)의 정보를 바탕으로 부하를 분산한다.          
      
- **IP 주소와 port 번호**를 이용하여 전달할 서버를 결정한다.       
- 예시: IP + Port > 213.12.32.123:80, 213.12.32.123:1024
- TCP, UDP Protocol
- 장점 : Port기반 스위칭 지원, VIP를 이용하여 여러대를 한대로 묶어 부하분산
- 주로 **Round Robin 방식 사용**    
- 하위 레이어의 정보(L3)도 활용하지만, 통상 L4 로드 밸런싱이라고 부른다.          

L4 로드 밸런서는 패킷 헤더의 `source IP`와 `destination IP`를       
**NAT(Network Address Translation)을 통해 바꿔서 서버에게 전달한다.**          
반대로 클라이언트로 패킷이 갈 때도 `source IP`와 `destination IP`를 바꿔서 
즉, **DSR 기술을 이용하여** 클라이언트에게 잘 전달되도록 한다.             
               
L2보다는 비용이 더 비싸다는 단점이 있지만,    
**IP와 포트번호를 활용하여 상대적으로 더 섬세한 라우팅이 가능하다.**       
내용물을 보지 않기 때문에 **TLS termination이 없다.**    

## L7(Application Layer)
L7 로드 밸런싱 : Layer 7(Application 계층)의 정보를 바탕으로 부하를 분산한다.          
                
- Layer 7(Application 계층)의 정보를 바탕으로 부하를 분산한다.              
- 예시 : IP + Port + 패킷내용(HttpMessage?) >               
213.12.32.123:80, 213.12.32.123:1024 + `GET/ img/aaa.jpg`       
- HTTP, FTP, SMTP Protocol    
    
L2, L4 로드 밸런싱은 물리적 단계에서 충분하지만,    
L7은 소프트웨어까지 사용해야 하기 때문에 비용이 더 비싸다.                 
대신, 가장 섬세한 라우팅이 가능하다.           
endpoint 별로 각기 다른 서버로 라우팅하거나,                  
라우팅한 서버에서 특정 `http status code`를 받았을 때 핸들링하는 등의 작업을 할 수 있다.                  
패킷의 내용을 복호화 해야하기 때문에 더 많은 비용이 든다.                   
                  
MSA를 생각하면 쉽다.       
`/category` 이거나, `/message` 같은 엔드포인트가 주어지면    
이에 해당하는 기능만 수행하는 서버에 분산처리를 할 수 있다.   
       

## 가중 라운드로빈 방식
각 서버에 가중치를 매기고 가중치가 높은 서버에 요청을 우선적으로 배정하는 방식
서버의 트래픽 처리 능력이 다른 경우 사용한다.

## 최소 연결 방식
요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에 트래픽을 배정하는 방식.
서버에 분배된 트래픽들이 일정하지 않은 경우에 적합하다.

## IP 해시 방식
클라이언트의 IP주소를 특정 서버로 매핑하여 요청을 처리하는 방식
사용자가 항상 동일한 서버로 연결된다.


# 다양한 로드밸런싱 알고리즘
## 라운드로빈 방식(Round Robin Method)
서버에 들어온 요청을 순서대로 돌아가며 배정하는 **순차 방식**이다.    
클라이언트의 요청을 순서대로 분배하기 때문에 여러 대의 서버가 동일한 스펙을 갖고 있고,    
서버와의 연결(세션)이 오래 지속되지 않는 경우에 활용하기 적합하다.   
다른 알고리즘에 비해서 가장 빠르다.      
        
## 가중 라운드로빈 방식(Weighted Round Robin Method)      
각각의 서버마다 가중치를 매기고 **가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분하는 방식이다.**       
주로 **서버의 트래픽 처리 능력이 상이한 경우 사용**되는 부하 분산 방식입니다.               
예를 들어 A라는 서버가 5라는 가중치를 갖고 B라는 서버가 2라는 가중치를 갖는다면,              
로드밸런서는 가중 라운드로빈 방식으로 A 서버에 5개 B 서버에 2개의 요청을 전달한다.               
     
## IP 해시 방식(IP Hash Method)     
클라이언트의 **IP 주소를 특정 서버로 매핑하여 요청**을 처리하는 방식이다.       
사용자의 **IP를 해싱해 로드를 분배**하기 때문에      
**사용자가 항상 동일한 서버로 연결되는 것을 보장**합니다.        
       
## 최소 연결 방식(Least Connection Method)
요청이 들어온 시점에 **가장 적은 연결상태를 보이는 서버에 우선적으로 트래픽을 배분**한다.         
즉, 현재 처리하고 있는 트래픽의 수치가 가장 적은 Server에게 트래픽을 분배한다.                  
자주 세션이 길어지거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합한 방식이다.                 
          
## 최소 리스폰타임(Least Response Time Method)   
서버의 현재 연결 상태와 응답시간을 모두 고려하여 트래픽을 배분한다.        
가장 적은 연결 상태와 가장 짧은 응답시간을 보이는 서버에 우선적으로 로드를 배분하는 방식이다.   

  
💡 로드 밸런싱을 설명해주세요.  
서버를 여러대 사용할 때 트래픽이 몰리면 여러 서버에 균등하게 트래픽을 분산 처리하는 기술입니다.     
   
💡 L4 로드 밸런싱과 L7 로드 밸런싱에 대해 설명하고, 차이를 말해보세요    
L4는 4계층인 네트워크 계층에서 사용됩니다.     
패킷 레벨에서만 트래픽을 분산하기 때문에 속도가 빠르고 효율성이 높습니다.    
L7 로드 밸런싱보다 저렴합니다.
L7는 7계층인 애플리케이션 계층에서 사용됩니다.    
HTTP Header, Cookie 등과 같이 사용자가 요청한 정보들을 바탕으로 트래픽을 분산하기 때문에 섬세한 라우팅이 가능하고 비정상적인 트래픽을 판별할 수 있습니다.    
L4 로드 밸런싱보다 가격이 비쌉니다.
    
💡 게이트웨이란?     
한 네트워크에서 다른 네트워크로 이동하기 위하여 거쳐야 하는 지점      
       
💡 서버에 트래픽이 주어졌을 때 어떻게 응답속도를 개선할 수 있는가요     
여러개의 서버에 트래픽을 균등하게 나눠주는 로드 밸런싱을 사용해 응답속도를 개선할 수 있습니다.      
