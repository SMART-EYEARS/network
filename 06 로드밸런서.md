# 로드밸런서     
> 일반적으로 서버 앞단에 위치하여 클라이언트 측의 요청을 분산해주는 프로그램        
   
시대의 흐름, 기술의 발전으로 이전과는 비교가 되지 않을 만큼 데이터가 생성되며     
이러한 데이터, 트래픽을 처리해야하기 위한 기술들 또한 등장하게 되었다.    
    
**로드밸런서란? :** 서버에 가해지는 부하를 분산해주는 **장치 또는 기술**을 통칭한다.     
분산 처리 시스템 중 하나라고 생각하는 것도 나쁘지 않다.        
   
또한, 여기서 중요한 것은 **장치** 또는 **기술**이라는 점이다.          
흔히 기술을 `로드밸런싱`이라고 생각할 수 있는데, 더 나아가 소프트웨어 로드밸런싱도 존재한다.      
대표적인 SW 로드밸런싱으로 [NGINX](https://ko.wikipedia.org/wiki/Nginx), [HAProxy](https://d2.naver.com/helloworld/284659) 그리고          
`Netflix`의 [Ribbon](https://github.com/Netflix/ribbon)이 있다. -> SpringBoot 2.4 에서부터 Netflix 의존성 점차 사라지기 시작할 예정         

로드 밸런서는 크게 2가지가 존재한다.   
     
- 운영체제 로드밸런서 : 물리적 프로세서간 작업 스케줄링 (사실, 운영체제 로드밸런서는 별개의 세상이다.)           
- 네트워크 로드밸런서: 사용가능한 백엔드에서 네트워크 작업 스케줄링  
         
다시 본론으로 돌아와, 로드밸런서는 그 종류와 분류가 너무 많다 😖        
그렇기 때문에 이번 로드밸런서 주제는 **HW** 그리고 **네트워크 로드밸런서**에 대해서 다루겠다.         
   
___  
   
앞서 로드 밸런서는 `서버에 가해지는 부하를 분산해주는 장치 또는 기술`이라 말했다.     
**그렇다면 모든 회사에서 로드밸런서를 사용하는 것이 좋지않을까? 🤔**            
   
로드밸런서는 주로 렌탈 형식으로 판매하는데 1G가 1년에 400만원, 비싼건 2000만원 까지도      
근데 중요한건 1개만 필요한게 아니라 여러 대가 필요하므로 회사 입장에서는 지출이 쎄다.       
      
그렇기 때문에 사업의 규모가 확장되고, 클라이언트의 수가 늘어나게 되어   
기존 서버만으로는 정상적인 서비스가 불가능하게 되었을 때 도입하면 된다.    
                    
**여담으로** 사업이 확장됨에 따라 증가되는 트래픽을 대처할 수 있는 방법은 크게 두 가지가 있다.  
      
* Scale up : 서버 자체의 성능을 높이는 것
* Scale out : 여러 대의 서버를 두는 것
         
`Scale up`은 쉽게 생각하면 기존 서버보다 성능이 좋은 서버로 교체한다고 생각해도 좋다.            
`Scale-out`은 기존의 서버외에도 추가로 서버를 중성하는 것을 의미하는데           
여러 대의 서버가 존재하면, 트래픽을 균등하게 분산해주어야 하므로 로드밸런싱이 반드시 필요하다.                  

         
# 로드 밸런서의 종류  
로드 밸런서는 OSI 7 Layer 처럼  
 
## L2(Data Link Layer)
- Mac Address Load Balancing
- 예시 : Mac > 80–00–20–30–1C-47
- 브릿지, 허브 등
- 장점 : 구조가 간단, 신뢰성이 높다, 가격저렴, 성능이 좋다.
- 단점 : Broadcast 패킷에 의해 성능저하 발생, 라우팅 등 상위레이어 프로토콜 기반 스위칭 불가
## L3(Network Layer)
- IP Address Load Balancing
- 예시 : IP > 213.12.32.123
- L2 + Routing
- Router, ICMP 프로토콜, IP
- 장점: Broadcast 트래픽으로 전체 성능 저하 방지, 트레픽체크
- 단점: 특정 프로토콜을 이용해야 스위칭 가능
## L4(Transport Layer)
- Transport Layer(IP+Port) Load Balancing
- 예시: IP+Port > 213.12.32.123:80, 213.12.32.123:1024
- TCP, UDP Protocol
- 장점 : Port기반 스위칭 지원, VIP를 이용하여 여러대를 한대로 묶어 부하분산
- 주로 Round Robin 방식 사용
## L7(Application Layer)
- Application Layer(사용자 Request) Load Balancing
- 예시 : IP+Port+패킷 내용 >
213.12.32.123:80, 213.12.32.123:1024 + GET/ img/aaa.jpg
- HTTP, FTP, SMTP Protocol

     
# 다양한 로드밸런싱 알고리즘
## 라운드로빈 방식(Round Robin Method)
서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식입니다. 클라이언트의 요청을 순서대로 분배하기 때문에 여러 대의 서버가 동일한 스펙을 갖고 있고, 서버와의 연결(세션)이 오래 지속되지 않는 경우에 활용하기 적합합니다.

## 가중 라운드로빈 방식(Weighted Round Robin Method)
각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분합니다. 주로 서버의 트래픽 처리 능력이 상이한 경우 사용되는 부하 분산 방식입니다. 예를 들어 A라는 서버가 5라는 가중치를 갖고 B라는 서버가 2라는 가중치를 갖는다면, 로드밸런서는 라운드로빈 방식으로 A 서버에 5개 B 서버에 2개의 요청을 전달합니다.

## IP 해시 방식(IP Hash Method)
클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식입니다. 사용자의 IP를 해싱해(Hashing, 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑하는 것, 또는 그러한 함수) 로드를 분배하기 때문에 사용자가 항상 동일한 서버로 연결되는 것을 보장합니다. 

## 최소 연결 방식(Least Connection Method)
요청이 들어온 시점에 가장 적은 연결상태를 보이는 서버에 우선적으로 트래픽을 배분합니다. 자주 세션이 길어지거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합한 방식입니다.

## 최소 리스폰타임(Least Response Time Method)
서버의 현재 연결 상태와 응답시간(Response Time, 서버에 요청을 보내고 최초 응답을 받을 때까지 소요되는 시간)을 모두 고려하여 트래픽을 배분합니다. 가장 적은 연결 상태와 가장 짧은 응답시간을 보이는 서버에 우선적으로 로드를 배분하는 방식입니다.





💡 로드 밸런싱을 설명해주세요.
서버를 여러대 사용할 때 트래픽이 몰리면 여러 서버에 균등하게 트래픽을 분산 처리하는 기술입니다.
💡 L4 로드 밸런싱과 L7 로드 밸런싱에 대해 설명하고, 차이를 말해보세요
L4는 4계층인 네트워크 계층에서 사용됩니다. 패킷 레벨에서만 트래픽을 분산하기 때문에 속도가 빠르고 효율성이 높습니다. L7 로드 밸런싱보다 저렴합니다.
L7는 7계층인 애플리케이션 계층에서 사용됩니다. HTTP Header, Cookie 등과 같이 사용자가 요청한 정보들을 바탕으로 트래픽을 분산하기 때문에 섬세한 라우팅이 가능하고 비정상적인 트래픽을 판별할 수 있습니다. L4 로드 밸런싱보다 가격이 비쌉니다.
💡 게이트웨이란?
한 네트워크에서 다른 네트워크로 이동하기 위하여 거쳐야 하는 지점
💡 서버에 트래픽이 주어졌을 때 어떻게 응답속도를 개선할 수 있는가요
여러개의 서버에 트래픽을 균등하게 나눠주는 로드 밸런싱을 사용해 응답속도를 개선할 수 있습니다.
